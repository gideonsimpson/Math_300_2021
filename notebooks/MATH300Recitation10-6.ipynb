{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MATH 300: Numerical Analysis I Recitation\n",
    "\n",
    "## Instructor: Liam Doherty\n",
    "\n",
    "## Meeting Time/Place: W 11:00AM, Curtis 344\n",
    "\n",
    "### Office Availability: MRC hours MTR 5p-7p (M 5-7 & T 5-6 FTF, others online), or in Korman 257 by appointment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we will look at some problems from section 2.3 of the textbook on Newton's method and its extensions. Here are functions to perform Newton's Method, the Secant Method, and the Method of False Position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "newton (generic function with 1 method)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function newton(f::Function, df::Function, p₀::Real; abs_tol = 1e-5, max_iters = 100, verbose = true)\n",
    "    converged = false\n",
    "    n = 0\n",
    "    \n",
    "    p = p₀\n",
    "    while !converged\n",
    "        n += 1\n",
    "        p_old = p\n",
    "        \n",
    "        @assert df(p) != 0 \"The derivative evaluated at the current point is zero! Cannot proceed. Last point: $(p)\"\n",
    "        \n",
    "        # Main step for algorithm\n",
    "        p = p - f(p)/df(p)\n",
    "        \n",
    "        # Status updates\n",
    "        if verbose\n",
    "            println(\"Old p: $(p_old), New p: $(p), Iteration: $(n)\")\n",
    "        end\n",
    "        \n",
    "        # Check convergence\n",
    "        if abs(p - p_old) < abs_tol\n",
    "            converged = true\n",
    "            return p\n",
    "        end\n",
    "        \n",
    "        # Return if algorithm does not converge\n",
    "        if n == max_iters\n",
    "            println(\"Did not converge in $(max_iters) iterations! Returning last value of p.\")\n",
    "            return p\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "secant (generic function with 1 method)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function secant(f::Function, p₀::Real, p₁::Real; abs_tol = 1e-5, max_iters = 100, verbose = true)\n",
    "    converged = false\n",
    "    n = 0\n",
    "    \n",
    "    # pᵢ is the oldest point, pⱼ is the most recent known point, and we are computing pₖ.\n",
    "    pᵢ = p₀; pⱼ = p₁ \n",
    "    while !converged\n",
    "        n += 1\n",
    "        \n",
    "        @assert f(pᵢ) != f(pⱼ) \"The secant evaluated at the current points has slope zero!\n",
    "                                Cannot proceed. Last point: $(pⱼ)\"\n",
    "        \n",
    "        # Main step for algorithm\n",
    "        pₖ = pⱼ - f(pⱼ)*(pⱼ - pᵢ)/(f(pⱼ) - f(pᵢ))\n",
    "        \n",
    "        # Status updates\n",
    "        if verbose\n",
    "            println(\"Old p values: ($(pᵢ), $(pⱼ)), New p values: ($(pⱼ), $(pₖ)), Iteration: $(n)\")\n",
    "        end\n",
    "        \n",
    "        # Check convergence\n",
    "        if abs(pⱼ - pₖ) < abs_tol\n",
    "            converged = true\n",
    "            return pₖ\n",
    "        end\n",
    "        \n",
    "        # Return if algorithm does not converge\n",
    "        if n == max_iters\n",
    "            println(\"Did not converge in $(max_iters) iterations! Returning last value of p.\")\n",
    "            return pₖ\n",
    "        end\n",
    "        \n",
    "        # Update current values for pᵢ and pⱼ\n",
    "        pᵢ = pⱼ; pⱼ = pₖ\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false_position (generic function with 1 method)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function false_position(f::Function, p₀::Real, p₁::Real; abs_tol = 1e-5, max_iters = 100, verbose = true)\n",
    "    converged = false\n",
    "    n = 0\n",
    "    \n",
    "    # pᵢ is the oldest point, pⱼ is the most recent known point, and we are computing pₖ.\n",
    "    pᵢ = p₀; pⱼ = p₁ \n",
    "    while !converged\n",
    "        n += 1\n",
    "        \n",
    "        @assert f(pᵢ) != f(pⱼ) \"The secant evaluated at the current points has slope zero!\n",
    "                                Cannot proceed. Last point: $(pⱼ)\"\n",
    "        \n",
    "        # Main step for algorithm\n",
    "        pₖ = pⱼ - f(pⱼ)*(pⱼ - pᵢ)/(f(pⱼ) - f(pᵢ))\n",
    "        \n",
    "        # Status updates\n",
    "        if verbose\n",
    "            println(\"Old p values: ($(pᵢ), $(pⱼ)), New p values: ($(pⱼ), $(pₖ)), Iteration: $(n)\")\n",
    "        end\n",
    "        \n",
    "        # Check convergence\n",
    "        if abs(pⱼ - pₖ) < abs_tol\n",
    "            converged = true\n",
    "            return pₖ\n",
    "        end\n",
    "        \n",
    "        # Return if algorithm does not converge\n",
    "        if n == max_iters\n",
    "            println(\"Did not converge in $(max_iters) iterations! Returning last value of p.\")\n",
    "            return pₖ\n",
    "        end\n",
    "        \n",
    "        # Check brackets and update the current value for pᵢ or pⱼ\n",
    "        if f(pᵢ)*f(pₖ) > 0\n",
    "            pᵢ = pₖ\n",
    "        elseif f(pⱼ)*f(pₖ) > 0\n",
    "            pⱼ = pₖ\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2.3.1\n",
    "\n",
    "Let $f(x) = x^{2} - 6$ and $p_{0} = 1$. Use Newton's method to find $p_{2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution:\n",
    "\n",
    "Recall the iteration for Newton's method: $\\newline \\newline$\n",
    "$$\n",
    "x_{n + 1} = x_{n} - \\frac{f(x_{n})}{f'(x_{n})}.\n",
    "\\newline\n",
    "$$\n",
    "To use this formula, we need to find $f'(x)$: $\\newline \\newline$\n",
    "$$\n",
    "f'(x) = 2x\n",
    "\\newline\n",
    "$$\n",
    "Now, we can use the iteration to find $p_{1}$: $\\newline \\newline$\n",
    "$$\n",
    "\\begin{align*}\n",
    "    p_{1} &= p_{0} - \\frac{f(p_{0})}{f'(p_{0})} \\\\\n",
    "    &= 1 - \\frac{f(1)}{f'(1)} \\\\\n",
    "    &= 1 - \\frac{-5}{2} \\\\\n",
    "    &= \\frac{7}{2} \\\\\n",
    "    &= 3.5.\n",
    "\\end{align*}\n",
    "\\newline\n",
    "$$\n",
    "We can then take $p_{1}$ and use it to find $p_{2}$: $\\newline \\newline$\n",
    "$$\n",
    "\\begin{align*}\n",
    "    p_{2} &= p_{1} - \\frac{f(p_{1})}{f'(p_{1})} \\\\\n",
    "    &= \\frac{7}{2} - \\frac{(7/2)^{2} - 6}{2(7/2)} \\\\\n",
    "    &= \\frac{7}{2} - \\frac{\\frac{49}{4} - 6}{7} \\\\\n",
    "    &= \\frac{7}{2} - \\frac{\\frac{25}{4}}{7} \\\\\n",
    "    &= \\frac{7}{2} - \\frac{25}{28} \\\\\n",
    "    &= \\frac{73}{28} \\\\\n",
    "    &\\approx 2.6071\n",
    "\\end{align*}\n",
    "\\newline\n",
    "$$\n",
    "Of course we can verify this using our code written above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old p: 1, New p: 3.5, Iteration: 1\n",
      "Old p: 3.5, New p: 2.607142857142857, Iteration: 2\n",
      "Old p: 2.607142857142857, New p: 2.454256360078278, Iteration: 3\n",
      "Old p: 2.454256360078278, New p: 2.4494943716069653, Iteration: 4\n",
      "Old p: 2.4494943716069653, New p: 2.4494897427875517, Iteration: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.4494897427875517"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x) = x^2 - 6\n",
    "df(x) = 2*x\n",
    "newton(f, df, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2.3.2\n",
    "\n",
    "Let $f(x) = -x^{3} - \\cos(x)$ and $p_{0} = -1$. Use Newton's method to find $p_{2}$. Could $p_{0} = 0$ be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution:\n",
    "\n",
    "We again need the derivative of $f$. We have $\\newline \\newline$\n",
    "$$\n",
    "f'(x) = -3x^{2} + \\sin(x).\n",
    "\\newline\n",
    "$$\n",
    "Then, we get $\\newline \\newline$\n",
    "$$\n",
    "\\begin{align*}\n",
    "    p_{1} &= p_{0} - \\frac{f(p_{0})}{f'(p_{0})} \\\\\n",
    "    &= -1 - \\frac{f(-1)}{f'(-1)} \\\\\n",
    "    &= -1 - \\frac{1 - \\cos (-1)}{-3 + \\sin (-1)} \\\\\n",
    "    &\\approx -1 - \\frac{0.4600}{-3.8415} \\\\\n",
    "    &\\approx -0.8803.\n",
    "\\end{align*}\n",
    "\\newline\n",
    "$$\n",
    "Now, we compute $p_{2}$: $\\newline \\newline$\n",
    "$$\n",
    "\\begin{align*}\n",
    "    p_{2} &= p_{1} - \\frac{f(p_{1})}{f'(p_{1})} \\\\\n",
    "    &\\approx -0.8803 - \\frac{-(-0.8803)^{3} - \\cos (-0.8803)}{-3(-0.8803)^{2} + \\sin(-0.8803)} \\\\\n",
    "    &\\approx -0.8656\n",
    "\\end{align*}\n",
    "\\newline\n",
    "$$\n",
    "Again, we verify with the Newton method code above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old p: -1, New p: -0.880332899571582, Iteration: 1\n",
      "Old p: -0.880332899571582, New p: -0.8656841631760818, Iteration: 2\n",
      "Old p: -0.8656841631760818, New p: -0.865474075952977, Iteration: 3\n",
      "Old p: -0.865474075952977, New p: -0.8654740331016162, Iteration: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.8654740331016162"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g(x) = -x^3 - cos(x)\n",
    "dg(x) = -3*x^2 + sin(x)\n",
    "newton(g, dg, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how quickly these problems converged within the tolerance (default tolerance was set to $10^{-5}$). This is much faster convergence than methods like the bisection method. Formally, Newton's method has a quadratic rate of convergence, while the bisection method has a linear rate of convergence. This is a trade-off to be made with the strength of the assumptions: The bisection method requires only continuity on the interval, whereas Newton's method requires differentiability. The other downside of Newton's method (although not large enough a downside to preclude its use in practice) is that if your iteration arrives at a point $p_{k}$ for which $f'(p_{k}) = 0$, the iteration cannot proceed. Algebraically, this corresponds to dividing by zero. Geometrically, this corresponds to the fact that a nonzero constant function has no zeros! In essence, the algorithm cannot find the next iterate because it is supposed to be the zero of the tangent line, but if the tangent line has no zero to use, the method will terminate.\n",
    "\n",
    "To illustrate this, consider the above problem with the starting point $p_{0} = 0$. Then $\\newline \\newline$\n",
    "$$\n",
    "f'(p_{0}) = f'(0) = -3(0)^{3} + \\sin 0 = 0 + 0 = 0.\n",
    "\\newline\n",
    "$$\n",
    "The algorithm written above throws an error in this case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "AssertionError: The derivative evaluated at the current point is zero! Cannot proceed. Last point: 0",
     "output_type": "error",
     "traceback": [
      "AssertionError: The derivative evaluated at the current point is zero! Cannot proceed. Last point: 0",
      "",
      "Stacktrace:",
      " [1] newton(f::typeof(g), df::typeof(dg), p₀::Int64; abs_tol::Float64, max_iters::Int64, verbose::Bool)",
      "   @ Main ./In[31]:10",
      " [2] newton(f::Function, df::Function, p₀::Int64)",
      "   @ Main ./In[31]:2",
      " [3] top-level scope",
      "   @ In[36]:1",
      " [4] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [5] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1094"
     ]
    }
   ],
   "source": [
    "newton(g, dg, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2.3.3\n",
    "\n",
    "Let $f(x) = x^{2} - 6$. With $p_{0} = 3$ and $p_{1} = 2$, find $p_{3}$.\n",
    "\n",
    "(a) Use the Secant method.\n",
    "\n",
    "(b) Use the method of False Position.\n",
    "\n",
    "(c) Which of part (a) or (b) is closer to $\\sqrt{6}$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by using the Secant method. The iteration is given by $\\newline \\newline$\n",
    "$$\n",
    "x_{n + 1} = x_{n} - f(x_{n})\\frac{x_{n} - x_{n - 1}}{f(x_{n}) - f(x_{n - 1})}.\n",
    "\\newline\n",
    "$$\n",
    "Of course, this is an extension of Newton's method where we have discretized $f'(x_{n})$ using a (backward) finite difference approximation. We use this to find $p_{2}$: $\\newline \\newline$\n",
    "$$\n",
    "\\begin{align*}\n",
    "    p_{2} &= p_{1} - f(p_{1})\\frac{p_{1} - p_{0}}{f(p_{1}) - f(p_{0})} \\\\\n",
    "    &= 2 - (-2)\\frac{2 - 3}{-2 - 3} \\\\\n",
    "    &= 2 + 2\\frac{1}{5} \\\\\n",
    "    &= \\frac{12}{5} \\\\\n",
    "    &= 2.4.\n",
    "\\end{align*}\n",
    "\\newline\n",
    "$$\n",
    "Now, we compute $p_{3}$: $\\newline \\newline$\n",
    "$$\n",
    "\\begin{align*}\n",
    "    p_{3} &= p_{2} - f(p_{2})\\frac{p_{2} - p_{1}}{f(p_{2}) - f(p_{1})} \\\\\n",
    "    &= 2.4 - (2.4^{2} - 6)\\frac{2.4 - 2}{2.4^{2} - 2^{2}} \\\\\n",
    "    &= 2.4 + 0.24\\frac{0.4}{1.76} \\\\\n",
    "    &\\approx 2.4545.\n",
    "\\end{align*}\n",
    "\\newline\n",
    "$$\n",
    "We check this with the secant function written above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old p values: (3, 2), New p values: (2, 2.4), Iteration: 1\n",
      "Old p values: (2, 2.4), New p values: (2.4, 2.4545454545454546), Iteration: 2\n",
      "Old p values: (2.4, 2.4545454545454546), New p values: (2.4545454545454546, 2.449438202247191), Iteration: 3\n",
      "Old p values: (2.4545454545454546, 2.449438202247191), New p values: (2.449438202247191, 2.44948968964799), Iteration: 4\n",
      "Old p values: (2.449438202247191, 2.44948968964799), New p values: (2.44948968964799, 2.449489742783737), Iteration: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.449489742783737"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secant(f, 3, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll use the method of False Position. This is a variant on the secant method that makes use of bracketing. Again, we use the iteration $\\newline \\newline$\n",
    "$$\n",
    "x_{n + 1} = x_{n} - f(x_{n})\\frac{x_{n} - x_{n - 1}}{f(x_{n}) - f(x_{n - 1})},\n",
    "\\newline\n",
    "$$\n",
    "but we will make use of bracketing to determine whether to replace $x_{n}$ or $x_{n - 1}$ with $x_{n + 1}$. The first iteration is exactly the same, so we obtain $p_{2} = 2.4$. Now, $f(2.4) = 5.76 - 6 = -0.24 < 0$. We want to maintain opposite signs of $f$ with our two points, so we replace $p_{1} = 2$, since $f(2) = -2 < 0$ and $f(3) = 3 > 0$. Therefore, our two points going into the next iteration are $(p_{0}, p_{2}) = (3, 2.4)$. We now carry out the next iteration to find $p_{3}$: $\\newline \\newline$\n",
    "$$\n",
    "\\begin{align*}\n",
    "    p_{3} &= p_{2} - f(p_{2})\\frac{p_{2} - p_{0}}{f(p_{2}) - f(p_{0})} \\\\\n",
    "    &= 2.4 - (-0.24)\\frac{2.4 - 3}{-0.24 - 3} \\\\\n",
    "    &= 2.4 + 0.24\\frac{-0.6}{-3.24} \\\\\n",
    "    &\\approx 2.4444.\n",
    "\\end{align*}\n",
    "\\newline\n",
    "$$\n",
    "We again verify this with code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old p values: (3, 2), New p values: (2, 2.4), Iteration: 1\n",
      "Old p values: (3, 2.4), New p values: (2.4, 2.444444444444444), Iteration: 2\n",
      "Old p values: (3, 2.444444444444444), New p values: (2.444444444444444, 2.4489795918367347), Iteration: 3\n",
      "Old p values: (3, 2.4489795918367347), New p values: (2.4489795918367347, 2.449438202247191), Iteration: 4\n",
      "Old p values: (3, 2.449438202247191), New p values: (2.449438202247191, 2.4494845360824744), Iteration: 5\n",
      "Old p values: (3, 2.4494845360824744), New p values: (2.4494845360824744, 2.449489216799092), Iteration: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.449489216799092"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_position(f, 3, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then see which of these methods produces a better approximation to $\\sqrt{6}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secant Error: 5.591083152012288e-13\n",
      "False Position Error: 5.259840860638576e-7\n"
     ]
    }
   ],
   "source": [
    "secant_approximation = secant(f, 3, 2, verbose = false);\n",
    "println(\"Secant Error: $(abs(secant_approximation - sqrt(6)))\")\n",
    "\n",
    "false_position_approximation = false_position(f, 3, 2, verbose = false);\n",
    "println(\"False Position Error: $(abs(false_position_approximation - sqrt(6)))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the Secant method gives a much better approximation. The Secant method is indeed faster than the method of False Position, but the secant method can sometimes fail to converge, whereas due to the bracketing of the method of False Position, it will always converge. This is another example of the trade-off between two variants on Newton's method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
